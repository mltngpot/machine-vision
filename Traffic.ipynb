{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPwsDu4uCJ56q32Y3df+Kxe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mltngpot/machine-vision/blob/main/Traffic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# determine working directory\n",
        "import os\n",
        "HOME = os.getcwd()\n",
        "print(HOME)"
      ],
      "metadata": {
        "id": "z4__Hqkozf2h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# connect with github\n",
        "https://github.com/mltngpot/machine-vision.git\n",
        "# set video path\n",
        "SOURCE_VIDEO_PATH = f\"{HOME}/vehicle-counting.mp4\""
      ],
      "metadata": {
        "collapsed": true,
        "id": "YmwvMEqmzpYZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install ultralytics # already installed\n",
        "\n",
        "from IPython import display\n",
        "display.clear_output()\n",
        "\n",
        "import ultralytics\n",
        "ultralytics.checks()\n",
        "\n",
        "\n",
        "#!pip install supervision # already installed\n",
        "\n",
        "from IPython import display\n",
        "display.clear_output()\n",
        "\n",
        "import supervision as sv\n",
        "print('supervision.__version__:', sv.__version__)"
      ],
      "metadata": {
        "id": "yDCVdEuKzweG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# select model\n",
        "MODEL = 'yolov8x.pt'"
      ],
      "metadata": {
        "id": "6Rw8dUm-z0is"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import YOLO and create model\n",
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO(MODEL)\n",
        "model.fuse()\n",
        "\n",
        "\n",
        "\n",
        "# dict mapping class_id to class_name\n",
        "CLASS_NAMES_DICT = model.model.names\n",
        "\n",
        "# class_ids of interest : car, motorcycle, bus, and truck\n",
        "selected_classes = [2, 3, 5, 7]"
      ],
      "metadata": {
        "id": "sLEwPvACz5zG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initial frame generations for annotations\n",
        "import supervision as sv\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# create frame generator\n",
        "generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH)\n",
        "# Note: since this tutorial, the API has changed, so I am changing some parts after reading API\n",
        "# create instance of LabelAnnotator\n",
        "label_annotator = sv.LabelAnnotator(text_thickness=4, text_scale=2, text_position=sv.Position.TOP_CENTER)\n",
        "# get first frame of the video\n",
        "iterator = iter(generator)\n",
        "frame = next(iterator)\n",
        "# model prediction on single frame and conversion to supervision Detections\n",
        "results = model(frame, verbose=False)[0]\n",
        "\n",
        "# convert to Detections\n",
        "detections = sv.Detections.from_ultralytics(results)\n",
        "# only consider class id from selected_classes from above\n",
        "detections = detections[np.isin(detections.class_id, selected_classes)]\n",
        "\n",
        "# format custom labels\n",
        "labels = [\n",
        "    f'{CLASS_NAMES_DICT[class_id]}{confidence:0.2f}'\n",
        "    for confidence, class_id in zip(detections.confidence, detections.class_id)\n",
        "]\n",
        "\n",
        "# annotate and display frame\n",
        "anotated_frame = label_annotator.annotate(scene=frame, detections=detections, labels=labels)\n",
        "\n",
        "%matplotlib inline\n",
        "sv.plot_image(anotated_frame, (16,16))"
      ],
      "metadata": {
        "id": "uP2ELr9f0Pjl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# settings for counting line\n",
        "LINE_START = sv.Point(50, 1500)\n",
        "LINE_END = sv.Point(3840-50, 1500)\n",
        "# output video path\n",
        "TARGET_VIDEO_PATH = f'{HOME}/vehicle-counting-results-with-counter.mp4'"
      ],
      "metadata": {
        "id": "8M1M4dz70YMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get video info\n",
        "sv.VideoInfo.from_video_path(SOURCE_VIDEO_PATH)"
      ],
      "metadata": {
        "id": "DtuwTw4_0vDz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "srTCf17sxvkh"
      },
      "outputs": [],
      "source": [
        "# create bytetracker instance\n",
        "byte_tracker = sv.ByteTrack() # defaults track_thresh=0.25, track_buffer=30, match_thresh=0.8, frame_rate=30)\n",
        "\n",
        "# create videoInfo instance\n",
        "video_info = sv.VideoInfo.from_video_path(SOURCE_VIDEO_PATH)\n",
        "\n",
        "# create frame generator\n",
        "generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH)\n",
        "\n",
        "# create LineZone instance\n",
        "line_zone = sv.LineZone(start=LINE_START, end=LINE_END)\n",
        "\n",
        "# create instance of BoxAnnotator\n",
        "label_annotator = sv.LabelAnnotator(text_thickness=4, text_scale=2, text_position=sv.Position.TOP_CENTER)\n",
        "\n",
        "# create instance of TraceAnnotator\n",
        "trace_annotator = sv.TraceAnnotator(thickness=4, trace_length=50)\n",
        "\n",
        "# create LineZoneAnnotator instance\n",
        "line_zone_annotator = sv.LineZoneAnnotator(thickness=4, text_thickness=4, text_scale=2)\n",
        "\n",
        "# define call back function to be used in video processing\n",
        "def callback(frame: np.ndarray, index: int) -> np.ndarray:\n",
        "    # model prediction on single frame and conversion to supervision Detections\n",
        "    results = model(frame, verbose=False)[0]\n",
        "    detections = sv.Detections.from_ultralytics(results)\n",
        "    # only consider class id from selected_classes define above\n",
        "    detections = detections[np.isin(detections.class_id, selected_classes)]\n",
        "    # tracking detections\n",
        "    detections = byte_tracker.update_with_detections(detections)\n",
        "    labels = [\n",
        "        f\"#{tracker_id} {model.model.names[class_id]} {confidence:0.2f}\"\n",
        "        for confidence, class_id, tracker_id\n",
        "        in zip(detections.confidence, detections.class_id, detections.tracker_id)\n",
        "    ]\n",
        "    annotated_frame = trace_annotator.annotate(\n",
        "        scene=frame.copy(),\n",
        "        detections=detections\n",
        "    )\n",
        "    annotated_frame=label_annotator.annotate(\n",
        "        scene=annotated_frame,\n",
        "        detections=detections,\n",
        "        labels=labels)\n",
        "\n",
        "    # update line counter\n",
        "    line_zone.trigger(detections)\n",
        "    # return frame with box and line annotated result\n",
        "    return  line_zone_annotator.annotate(annotated_frame, line_counter=line_zone)\n",
        "\n",
        "# process the whole video\n",
        "sv.process_video(\n",
        "    source_path = SOURCE_VIDEO_PATH,\n",
        "    target_path = TARGET_VIDEO_PATH,\n",
        "    callback=callback\n",
        ")"
      ]
    }
  ]
}