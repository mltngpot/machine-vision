{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLOv8n summary (fused): 168 layers, 3,151,904 parameters, 0 gradients, 8.7 GFLOPs\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from collections import defaultdict\n",
    "import math\n",
    "from sklearn.cluster import KMeans\n",
    "import webcolors\n",
    "MODEL = 'yolov8n.pt'\n",
    "\n",
    "model = YOLO(MODEL)\n",
    "model.fuse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vehicle_color(image, bbox):\n",
    "    \"\"\"\n",
    "    Use KMeans clustering to determine the dominant color of a vehicle.\n",
    "\n",
    "    Parameters:\n",
    "    - image: numpy array representing the image (H x W x C).\n",
    "    - bbox: list or tuple of coordinates (x1, y1, x2, y2).\n",
    "\n",
    "    Returns:\n",
    "    - Color name derived from the dominant RGB color.\n",
    "    \"\"\"\n",
    "    x1, y1, x2, y2 = [int(coord) for coord in bbox]\n",
    "\n",
    "    x1, y1 = max(0, x1), max(0, y1)\n",
    "    x2, y2 = min(image.shape[1], x2), min(image.shape[0], y2)\n",
    "\n",
    "    vehicle_image = image[y1:y2, x1:x2]\n",
    "    if vehicle_image.size == 0:\n",
    "        raise ValueError(\"The bounding box does not contain a valid region within the image.\")\n",
    "    # Reshape the image data for clustering (pixels x 3 channels)\n",
    "    data = vehicle_image.reshape(-1, 3)\n",
    "    kmeans = KMeans(n_clusters=3, random_state=0).fit(data)\n",
    "    dominant_color = kmeans.cluster_centers_[0]\n",
    "\n",
    "    rgb_color = [int(color) for color in dominant_color]\n",
    "\n",
    "    return get_color_name(rgb_color)\n",
    "\n",
    "def get_color_name(rgb_color):\n",
    "    rgb_color = tuple(rgb_color)\n",
    "    try:\n",
    "        return webcolors.rgb_to_name(rgb_color)\n",
    "    except ValueError:\n",
    "        closest_name = get_closest_color_name(rgb_color)\n",
    "        return closest_name\n",
    "\n",
    "def get_closest_color_name(rgb_color):\n",
    "    min_colours = {}\n",
    "    for name in webcolors.names(\"html4\"):\n",
    "        r_c, g_c, b_c = webcolors.name_to_rgb(name)\n",
    "        rd = (r_c - rgb_color[0]) ** 2\n",
    "        gd = (g_c - rgb_color[1]) ** 2\n",
    "        bd = (b_c - rgb_color[2]) ** 2\n",
    "        min_colours[(rd + gd + bd)] = name\n",
    "\n",
    "    return min_colours[min(min_colours.keys())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_vehicle_type(model, cls):\n",
    "    \"\"\"\n",
    "    Classify the vehicle type based on the class ID.\n",
    "    cls: class ID\n",
    "    \"\"\"\n",
    "    class_name = model.names[int(cls)]\n",
    "    if class_name in ['car', 'truck', 'bus', 'motorcycle']:\n",
    "        return class_name\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_in_out(center, line_in, line_out, vehicle_info, vehicle_id):\n",
    "    \"\"\"\n",
    "    Check if the vehicle has crossed the in/out line.\n",
    "    \"\"\"\n",
    "    if not vehicle_info[vehicle_id][\"in\"] and center[1] < line_in[1]:\n",
    "        vehicle_info[vehicle_id][\"in\"] = True\n",
    "    if not vehicle_info[vehicle_id][\"out\"] and center[1] > line_out[1]:\n",
    "        vehicle_info[vehicle_id][\"out\"] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_speed(trajectory, fps, distance_per_pixel):\n",
    "    \"\"\"\n",
    "    Calculate the vehicle speed based on the trajectory.\n",
    "    trajectory: a list of points representing the vehicle trajectory\n",
    "    fps: frame per second\n",
    "    distance_per_pixel: the distance represented by each pixel\n",
    "    \"\"\"\n",
    "    if len(trajectory) > 2:\n",
    "        p1 = np.array(trajectory[-2])\n",
    "        p2 = np.array(trajectory[-1])\n",
    "        distance = np.linalg.norm(p2 - p1) * distance_per_pixel\n",
    "        speed = distance * fps\n",
    "        return speed\n",
    "    return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(video_path, model, output_path='output.mp4'):\n",
    "    # Read video file\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # Get video properties\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    # Define the codec and create VideoWriter object for output\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Specify the codec\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "    # Dictionary to store information about vehicle color, type, ID, trajectory, and speed\n",
    "    vehicle_info = defaultdict(lambda: {\"color\": None, \"type\": None, \"trajectory\": [], \"in\": False, \"out\": False, \"speed\": 0.0})\n",
    "\n",
    "    # Define the position of in and out lines (x, y, x2, y2)\n",
    "    line_in = (100, 200, 500, 200)  # Replace with desired positions\n",
    "    line_out = (100, 300, 500, 300)\n",
    "\n",
    "    # Unit conversion for speed calculation (adjust based on frame rate and actual scene size)\n",
    "    distance_per_pixel = 0.05  # Example: each pixel represents 0.05 meters\n",
    "    max_distance = 50  # Maximum distance for associating objects between frames\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Use YOLOv8 for vehicle detection\n",
    "        results = model(frame)\n",
    "\n",
    "        detected_centers = []\n",
    "        current_frame_info = []\n",
    "\n",
    "        for result in results:\n",
    "            for bbox, confidence, cls in zip(result.boxes.xyxy, result.boxes.conf, result.boxes.cls):\n",
    "                class_name = classify_vehicle_type(model, cls)\n",
    "\n",
    "                if class_name:\n",
    "                    # Calculate the center of the bounding box\n",
    "                    bbox = bbox.cpu().numpy()\n",
    "                    center = (int((bbox[0] + bbox[2]) / 2), int((bbox[1] + bbox[3]) / 2))\n",
    "                    detected_centers.append(center)\n",
    "\n",
    "                    # Find existing vehicle or create a new one based on distance\n",
    "                    matched_id = None\n",
    "                    for vehicle_id, info in vehicle_info.items():\n",
    "                        if info[\"trajectory\"]:\n",
    "                            last_center = info[\"trajectory\"][-1]\n",
    "                            distance = np.linalg.norm(np.array(center) - np.array(last_center))\n",
    "                            if distance < max_distance:\n",
    "                                matched_id = vehicle_id\n",
    "                                break\n",
    "\n",
    "                    if matched_id is None:\n",
    "                        # Create a new vehicle ID if no match found\n",
    "                        matched_id = len(vehicle_info)\n",
    "\n",
    "                    vehicle_info[matched_id][\"trajectory\"].append(center)\n",
    "\n",
    "                    # Get vehicle color (record only once)\n",
    "                    if vehicle_info[matched_id][\"color\"] is None:\n",
    "                        vehicle_info[matched_id][\"color\"] = get_vehicle_color(frame, bbox)\n",
    "\n",
    "                    # Get vehicle type (record only once)\n",
    "                    if vehicle_info[matched_id][\"type\"] is None:\n",
    "                        vehicle_info[matched_id][\"type\"] = class_name\n",
    "\n",
    "                    # Store the current frame info for visualization\n",
    "                    current_frame_info.append((bbox, matched_id, vehicle_info[matched_id][\"color\"], class_name))\n",
    "\n",
    "                    # Check in and out lines\n",
    "                    check_in_out(center, line_in, line_out, vehicle_info, matched_id)\n",
    "\n",
    "        # Visualization of detection results and in/out lines\n",
    "        for bbox, vehicle_id, color, class_name in current_frame_info:\n",
    "            # Draw bounding box\n",
    "            x1, y1, x2, y2 = [int(coord) for coord in bbox]\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "            # Display vehicle info\n",
    "            trajectory = vehicle_info[vehicle_id][\"trajectory\"]\n",
    "            speed = calculate_speed(trajectory, fps, distance_per_pixel)\n",
    "            vehicle_info[vehicle_id][\"speed\"] = speed\n",
    "            cv2.putText(frame, f\"{color}, {class_name}, Speed: {speed:.2f} m/s\", (x1, y1 - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "\n",
    "        # Draw in and out lines\n",
    "        cv2.line(frame, (line_in[0], line_in[1]), (line_in[2], line_in[3]), (0, 0, 255), 2)\n",
    "        cv2.line(frame, (line_out[0], line_out[1]), (line_out[2], line_out[3]), (255, 0, 0), 2)\n",
    "\n",
    "        # Write the processed frame to the output video\n",
    "        out.write(frame)\n",
    "\n",
    "    # Release video capture and writer\n",
    "    cap.release()\n",
    "    out.release()\n",
    "\n",
    "    # Count the number of vehicles by color and type\n",
    "    color_count = defaultdict(int)\n",
    "    type_count = defaultdict(int)\n",
    "    for info in vehicle_info.values():\n",
    "        if info[\"color\"]:\n",
    "            color_count[info[\"color\"]] += 1\n",
    "        if info[\"type\"]:\n",
    "            type_count[info[\"type\"]] += 1\n",
    "\n",
    "    print(\"Vehicle Color Statistics:\")\n",
    "    for color, count in color_count.items():\n",
    "        print(f\"{color}: {count}\")\n",
    "\n",
    "    print(\"\\nVehicle Type Statistics:\")\n",
    "    for v_type, count in type_count.items():\n",
    "        print(f\"{v_type}: {count}\")\n",
    "\n",
    "    print(f\"\\nProcessed video saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 cars, 1 bench, 48.8ms\n",
      "Speed: 0.0ms preprocess, 48.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "HTML4 is not a supported specification for color name lookups; supported specifications are: ('html4', 'css2', 'css21', 'css3').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 32\u001b[0m, in \u001b[0;36mget_color_name\u001b[1;34m(rgb_color)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwebcolors\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrgb_to_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrgb_color\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\zrinf\\OneDrive\\Documents\\python_workshop\\.venv\\Lib\\site-packages\\webcolors\\_conversion.py:239\u001b[0m, in \u001b[0;36mrgb_to_name\u001b[1;34m(rgb_triplet, spec)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;124;03mConvert a 3-:class:`tuple` of :class:`int`, suitable for use in an ``rgb()``\u001b[39;00m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;124;03mcolor triplet, to its corresponding normalized color name, if any such name exists.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    237\u001b[0m \n\u001b[0;32m    238\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 239\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhex_to_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrgb_to_hex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnormalize_integer_triplet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrgb_triplet\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspec\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\zrinf\\OneDrive\\Documents\\python_workshop\\.venv\\Lib\\site-packages\\webcolors\\_conversion.py:154\u001b[0m, in \u001b[0;36mhex_to_name\u001b[1;34m(hex_value, spec)\u001b[0m\n\u001b[0;32m    153\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m name\n\u001b[1;32m--> 154\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhex_value\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m has no defined color name in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspec\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: \"#dccdd0\" has no defined color name in css3.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m video_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      5\u001b[0m output_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../demo/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_name\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_output.mp4\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 6\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[46], line 64\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(video_path, model, output_path)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# Get vehicle color (record only once)\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m vehicle_info[matched_id][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolor\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m     vehicle_info[matched_id][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolor\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mget_vehicle_color\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# Get vehicle type (record only once)\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m vehicle_info[matched_id][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "Cell \u001b[1;32mIn[42], line 27\u001b[0m, in \u001b[0;36mget_vehicle_color\u001b[1;34m(image, bbox)\u001b[0m\n\u001b[0;32m     23\u001b[0m dominant_color \u001b[38;5;241m=\u001b[39m kmeans\u001b[38;5;241m.\u001b[39mcluster_centers_[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     25\u001b[0m rgb_color \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mint\u001b[39m(color) \u001b[38;5;28;01mfor\u001b[39;00m color \u001b[38;5;129;01min\u001b[39;00m dominant_color]\n\u001b[1;32m---> 27\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_color_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrgb_color\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[42], line 34\u001b[0m, in \u001b[0;36mget_color_name\u001b[1;34m(rgb_color)\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m webcolors\u001b[38;5;241m.\u001b[39mrgb_to_name(rgb_color)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m---> 34\u001b[0m     closest_name \u001b[38;5;241m=\u001b[39m \u001b[43mget_closest_color_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrgb_color\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m closest_name\n",
      "Cell \u001b[1;32mIn[42], line 39\u001b[0m, in \u001b[0;36mget_closest_color_name\u001b[1;34m(rgb_color)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_closest_color_name\u001b[39m(rgb_color):\n\u001b[0;32m     38\u001b[0m     min_colours \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m---> 39\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[43mwebcolors\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHTML4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     40\u001b[0m         r_c, g_c, b_c \u001b[38;5;241m=\u001b[39m webcolors\u001b[38;5;241m.\u001b[39mname_to_rgb(name)\n\u001b[0;32m     41\u001b[0m         rd \u001b[38;5;241m=\u001b[39m (r_c \u001b[38;5;241m-\u001b[39m rgb_color[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\zrinf\\OneDrive\\Documents\\python_workshop\\.venv\\Lib\\site-packages\\webcolors\\_definitions.py:340\u001b[0m, in \u001b[0;36mnames\u001b[1;34m(spec)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;124;03mReturn the list of valid color names for the given specification.\u001b[39;00m\n\u001b[0;32m    308\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    337\u001b[0m \n\u001b[0;32m    338\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m _SUPPORTED_SPECIFICATIONS:\n\u001b[1;32m--> 340\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(_SPECIFICATION_ERROR_TEMPLATE\u001b[38;5;241m.\u001b[39mformat(spec\u001b[38;5;241m=\u001b[39mspec))\n\u001b[0;32m    341\u001b[0m mapping \u001b[38;5;241m=\u001b[39m _names_to_hex[spec]\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28msorted\u001b[39m(mapping\u001b[38;5;241m.\u001b[39mkeys()))\n",
      "\u001b[1;31mValueError\u001b[0m: HTML4 is not a supported specification for color name lookups; supported specifications are: ('html4', 'css2', 'css21', 'css3')."
     ]
    }
   ],
   "source": [
    "# Run the main function with your video path\n",
    "file_name = \"I94-US20-35.1.mp4\"\n",
    "video_path = f\"../data/{file_name}\"\n",
    "\n",
    "output_path = f\"../demo/{file_name.split('.')[0]}_output.mp4\"\n",
    "main(video_path, model, output_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
